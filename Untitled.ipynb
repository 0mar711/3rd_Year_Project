{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6349e609-913d-4963-ad8a-434617f389ee",
   "metadata": {},
   "source": [
    "# Explainer Dashboard website development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83fb1f98-0144-48eb-9d7e-5e9df2b0cc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import json\n",
    "import plotly.graph_objs as go\n",
    "import dill\n",
    "from joblib import load\n",
    "import plotly\n",
    "# Dash related imports\n",
    "from dash import Dash, html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# ExplainerDashboard related imports\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard, ExplainerHub\n",
    "from explainerdashboard.custom import *\n",
    "from explainerdashboard.explainers import BaseExplainer\n",
    "\n",
    "# Sklearn metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
    "\n",
    "# Flask for any additional web server operations\n",
    "from flask import Flask, redirect\n",
    "\n",
    "from custom_components import ThresholdAdjustmentComponent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffc7e97-9ccf-4a11-8f0e-09062041b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b02be9-8dda-4905-9b75-4a3c98a51c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09eab3-e86c-40ee-8706-365c235bb7b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# UNSW Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b47658e-07c1-4978-a2c0-a44a4c926865",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load UNSW Models and test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d67252-56bc-415c-a4fe-f0f9e50202d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1410e22-e7b0-4a59-9d3c-0e99e6bae944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "rf_classifier_UNSW_Default = load('datasets/explainerDashboardFiles/rf_classifierdefaultUNSW.joblib')\n",
    "XGB_classifier_UNSW_Default = xgb.XGBClassifier()\n",
    "XGB_classifier_UNSW_Default.load_model('datasets/explainerDashboardFiles/xgb_classifierdefaultUNSW.model')\n",
    "LSTM_classifier_UNSW_Default = load_model('datasets/explainerDashboardFiles/lstm_modeldefaultUNSW')\n",
    "RLDDQN_classifier_UNSW_Default = load_model('datasets/explainerDashboardFiles/RLDDQN_modeldefaultUNSW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "309469a8-752d-4149-9ed5-cd25b45b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_trainUNSW = pd.read_parquet('datasets/explainerDashboardFiles/X_trainUNSW.parquet')\n",
    "X_testUNSW = pd.read_parquet('datasets/explainerDashboardFiles/X_testUNSW.parquet')\n",
    "y_train_loaded = pd.read_parquet('datasets/explainerDashboardFiles/y_trainUNSW.parquet')\n",
    "y_test_loaded = pd.read_parquet('datasets/explainerDashboardFiles/y_testUNSW.parquet')\n",
    "AEerror_normal_loadedUNSW = np.load('datasets/explainerDashboardFiles/AEerror_normalUNSW.npy')\n",
    "AEerror_anomalies_loadedUNSW = np.load('datasets/explainerDashboardFiles/AEerror_anomaliesUNSW.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b40288a-daec-4ae4-9e96-212f56f5f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainUNSW = y_train_loaded['target']\n",
    "y_testUNSW = y_test_loaded['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c91bd1-9df9-495e-9d64-19fc645e3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl',\n",
       "       'sload', 'dload',\n",
       "       ...\n",
       "       'state_CLO', 'state_CON', 'state_ECO', 'state_FIN', 'state_INT',\n",
       "       'state_PAR', 'state_REQ', 'state_RST', 'state_URN', 'state_no'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainUNSW.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e55aee67-83c8-4f7f-bf3c-9f1f70a88aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the test labels\n",
    "# This assumes y_testUNSW is a pandas Series. If it's not, adjust accordingly.\n",
    "label_encoder.fit(y_testUNSW)\n",
    "\n",
    "# Encode the test labels\n",
    "y_testUNSW_encoded = label_encoder.transform(y_testUNSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a087aa67-d6f8-4bc3-83bf-bfbdfd3f01bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The test_size = 1 should be greater or equal to the number of classes = 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming X_testUNSW and y_testUNSW are loaded as shown in your code\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reduce the test set to 5% of its original size, maintaining the class ratio\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_testUNSW_reduced, _, y_testUNSW_reduced, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_testUNSW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_testUNSW_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Keep 5% of the original size\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_testUNSW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Stratify by y_testUNSW to keep the class ratio\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# For reproducibility\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2638\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2634\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1726\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m \n\u001b[0;32m   1698\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1726\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2128\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2126\u001b[0m     )\n\u001b[0;32m   2127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_test \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[1;32m-> 2128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2129\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe test_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_test, n_classes)\n\u001b[0;32m   2131\u001b[0m     )\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;66;03m# Find the sorted list of instances for each class:\u001b[39;00m\n\u001b[0;32m   2134\u001b[0m \u001b[38;5;66;03m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[39;00m\n\u001b[0;32m   2135\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\n\u001b[0;32m   2136\u001b[0m     np\u001b[38;5;241m.\u001b[39margsort(y_indices, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m\"\u001b[39m), np\u001b[38;5;241m.\u001b[39mcumsum(class_counts)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   2137\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The test_size = 1 should be greater or equal to the number of classes = 10"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_testUNSW and y_testUNSW are loaded as shown in your code\n",
    "\n",
    "# Reduce the test set to 5% of its original size, maintaining the class ratio\n",
    "X_testUNSW_reduced, _, y_testUNSW_reduced, _ = train_test_split(\n",
    "    X_testUNSW, \n",
    "    y_testUNSW_encoded, \n",
    "    test_size=1,  # Keep 5% of the original size\n",
    "    stratify=y_testUNSW,  # Stratify by y_testUNSW to keep the class ratio\n",
    "    random_state=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055f709-afae-4ae9-8dd8-20a34e39dbc0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initiate explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "986bb02d-a73a-4176-95fc-1930ef5083e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the SHAP GPUtree explainer\n",
    "# Note: Ensure your SHAP version supports GPUtree explainer for RandomForest models.\n",
    "#explainer = shap.GPUTreeExplainer(rf_classifier_UNSW_DefaultREDUCED, data=X_trainUNSW, model_output=\"probability\", algorithm=\"gpu_path_dependent\")\n",
    "#shap_values = explainer.shap_values(X_testUNSW_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5489d4cc-2302-43de-8670-9da95be08d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the one hot encodes\n",
    "cats = [\n",
    "    # For `proto` column\n",
    "    {'proto': ['proto_' + proto for proto in ['tcp', 'udp', 'arp', 'ospf', 'icmp', 'igmp', 'rtp', 'ddp', 'ipv6-frag', 'cftp', 'wsn', 'pvp', 'wb-expak', 'mtp', 'pri-enc', 'sat-mon', 'cphb', 'sun-nd', 'iso-ip', 'xtp', 'il', 'unas', 'mfe-nsp', '3pc', 'ipv6-route', 'idrp', 'bna', 'swipe', 'kryptolan', 'cpnx', 'rsvp', 'wb-mon', 'vmtp', 'ib', 'dgp', 'eigrp', 'ax.25', 'gmtp', 'pnni', 'sep', 'pgm', 'idpr-cmtp', 'zero', 'rvd', 'mobile', 'narp', 'fc', 'pipe', 'ipcomp', 'ipv6-no', 'sat-expak', 'ipv6-opts', 'snp', 'ipcv', 'br-sat-mon', 'ttp', 'tcf', 'nsfnet-igp', 'sprite-rpc', 'aes-sp3-d', 'sccopmce', 'sctp', 'qnx', 'scps', 'etherip', 'aris', 'pim', 'compaq-peer', 'vrrp', 'iatp', 'stp', 'l2tp', 'srp', 'sm', 'isis', 'smp', 'fire', 'ptp', 'crtp', 'sps', 'merit-inp', 'idpr', 'skip', 'any', 'larp', 'ipip', 'micp', 'encap', 'ifmp', 'tp++', 'a/n', 'ipv6', 'i-nlsp', 'ipx-n-ip', 'sdrp', 'tlsp', 'gre', 'mhrp', 'ddx', 'ippc', 'visa', 'secure-vmtp', 'uti', 'vines', 'crudp', 'iplt', 'ggp', 'ip', 'ipnip', 'st2', 'argus', 'bbn-rcc', 'egp', 'emcon', 'igp', 'nvp', 'pup', 'xnet', 'chaos', 'mux', 'dcn', 'hmp', 'prm', 'trunk-1', 'xns-idp', 'leaf-1', 'leaf-2', 'rdp', 'irtp', 'iso-tp4', 'netblt', 'trunk-2', 'cbt']]},\n",
    "    \n",
    "    # For `service` column\n",
    "    {'service': ['service_' + service for service in ['-', 'ftp', 'smtp', 'snmp', 'http', 'ftp-data', 'dns', 'ssh', 'radius', 'pop3', 'dhcp', 'ssl', 'irc']]},\n",
    "    \n",
    "    # For `state` column\n",
    "    {'state': ['state_' + state for state in ['FIN', 'INT', 'CON', 'ECO', 'REQ', 'RST', 'PAR', 'URN', 'no', 'ACC', 'CLO']]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92a52bb4-22fa-472b-b9e7-faca1e352792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'proto': ['proto_tcp',\n",
       "   'proto_udp',\n",
       "   'proto_arp',\n",
       "   'proto_ospf',\n",
       "   'proto_icmp',\n",
       "   'proto_igmp',\n",
       "   'proto_rtp',\n",
       "   'proto_ddp',\n",
       "   'proto_ipv6-frag',\n",
       "   'proto_cftp',\n",
       "   'proto_wsn',\n",
       "   'proto_pvp',\n",
       "   'proto_wb-expak',\n",
       "   'proto_mtp',\n",
       "   'proto_pri-enc',\n",
       "   'proto_sat-mon',\n",
       "   'proto_cphb',\n",
       "   'proto_sun-nd',\n",
       "   'proto_iso-ip',\n",
       "   'proto_xtp',\n",
       "   'proto_il',\n",
       "   'proto_unas',\n",
       "   'proto_mfe-nsp',\n",
       "   'proto_3pc',\n",
       "   'proto_ipv6-route',\n",
       "   'proto_idrp',\n",
       "   'proto_bna',\n",
       "   'proto_swipe',\n",
       "   'proto_kryptolan',\n",
       "   'proto_cpnx',\n",
       "   'proto_rsvp',\n",
       "   'proto_wb-mon',\n",
       "   'proto_vmtp',\n",
       "   'proto_ib',\n",
       "   'proto_dgp',\n",
       "   'proto_eigrp',\n",
       "   'proto_ax.25',\n",
       "   'proto_gmtp',\n",
       "   'proto_pnni',\n",
       "   'proto_sep',\n",
       "   'proto_pgm',\n",
       "   'proto_idpr-cmtp',\n",
       "   'proto_zero',\n",
       "   'proto_rvd',\n",
       "   'proto_mobile',\n",
       "   'proto_narp',\n",
       "   'proto_fc',\n",
       "   'proto_pipe',\n",
       "   'proto_ipcomp',\n",
       "   'proto_ipv6-no',\n",
       "   'proto_sat-expak',\n",
       "   'proto_ipv6-opts',\n",
       "   'proto_snp',\n",
       "   'proto_ipcv',\n",
       "   'proto_br-sat-mon',\n",
       "   'proto_ttp',\n",
       "   'proto_tcf',\n",
       "   'proto_nsfnet-igp',\n",
       "   'proto_sprite-rpc',\n",
       "   'proto_aes-sp3-d',\n",
       "   'proto_sccopmce',\n",
       "   'proto_sctp',\n",
       "   'proto_qnx',\n",
       "   'proto_scps',\n",
       "   'proto_etherip',\n",
       "   'proto_aris',\n",
       "   'proto_pim',\n",
       "   'proto_compaq-peer',\n",
       "   'proto_vrrp',\n",
       "   'proto_iatp',\n",
       "   'proto_stp',\n",
       "   'proto_l2tp',\n",
       "   'proto_srp',\n",
       "   'proto_sm',\n",
       "   'proto_isis',\n",
       "   'proto_smp',\n",
       "   'proto_fire',\n",
       "   'proto_ptp',\n",
       "   'proto_crtp',\n",
       "   'proto_sps',\n",
       "   'proto_merit-inp',\n",
       "   'proto_idpr',\n",
       "   'proto_skip',\n",
       "   'proto_any',\n",
       "   'proto_larp',\n",
       "   'proto_ipip',\n",
       "   'proto_micp',\n",
       "   'proto_encap',\n",
       "   'proto_ifmp',\n",
       "   'proto_tp++',\n",
       "   'proto_a/n',\n",
       "   'proto_ipv6',\n",
       "   'proto_i-nlsp',\n",
       "   'proto_ipx-n-ip',\n",
       "   'proto_sdrp',\n",
       "   'proto_tlsp',\n",
       "   'proto_gre',\n",
       "   'proto_mhrp',\n",
       "   'proto_ddx',\n",
       "   'proto_ippc',\n",
       "   'proto_visa',\n",
       "   'proto_secure-vmtp',\n",
       "   'proto_uti',\n",
       "   'proto_vines',\n",
       "   'proto_crudp',\n",
       "   'proto_iplt',\n",
       "   'proto_ggp',\n",
       "   'proto_ip',\n",
       "   'proto_ipnip',\n",
       "   'proto_st2',\n",
       "   'proto_argus',\n",
       "   'proto_bbn-rcc',\n",
       "   'proto_egp',\n",
       "   'proto_emcon',\n",
       "   'proto_igp',\n",
       "   'proto_nvp',\n",
       "   'proto_pup',\n",
       "   'proto_xnet',\n",
       "   'proto_chaos',\n",
       "   'proto_mux',\n",
       "   'proto_dcn',\n",
       "   'proto_hmp',\n",
       "   'proto_prm',\n",
       "   'proto_trunk-1',\n",
       "   'proto_xns-idp',\n",
       "   'proto_leaf-1',\n",
       "   'proto_leaf-2',\n",
       "   'proto_rdp',\n",
       "   'proto_irtp',\n",
       "   'proto_iso-tp4',\n",
       "   'proto_netblt',\n",
       "   'proto_trunk-2',\n",
       "   'proto_cbt']},\n",
       " {'service': ['service_-',\n",
       "   'service_ftp',\n",
       "   'service_smtp',\n",
       "   'service_snmp',\n",
       "   'service_http',\n",
       "   'service_ftp-data',\n",
       "   'service_dns',\n",
       "   'service_ssh',\n",
       "   'service_radius',\n",
       "   'service_pop3',\n",
       "   'service_dhcp',\n",
       "   'service_ssl',\n",
       "   'service_irc']},\n",
       " {'state': ['state_FIN',\n",
       "   'state_INT',\n",
       "   'state_CON',\n",
       "   'state_ECO',\n",
       "   'state_REQ',\n",
       "   'state_RST',\n",
       "   'state_PAR',\n",
       "   'state_URN',\n",
       "   'state_no',\n",
       "   'state_ACC',\n",
       "   'state_CLO']}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6b3c1d7-6e71-4723-a585-ae88c273c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = y_trainUNSW.unique().tolist()\n",
    "class_labels.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd79626-d52b-4794-ac77-e8a8b8bea5e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNSW XGBoost Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4a3a3d4-51d2-4db4-a8b9-0ba0bdd8f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features in the XGBoost model is: 196\n"
     ]
    }
   ],
   "source": [
    "num_features = len(XGB_classifier_UNSW_Default.feature_importances_)\n",
    "\n",
    "print(f\"The number of features in the XGBoost model is: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0a41652-709c-4521-af69-123d94c1f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected XGBClassifier model: Changing class type to XGBClassifierExplainer...\n",
      "model_output=='probability' does not work with multiclass XGBClassifier models, so settings model_output='logodds'...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:38:54] WARNING: D:\\bld\\xgboost-split_1705650032250\\work\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    }
   ],
   "source": [
    "#XGB_classifier_UNSW_Default\n",
    "explainer = ClassifierExplainer(\n",
    "    model=XGB_classifier_UNSW_Default,\n",
    "    X=X_testUNSW,\n",
    "    y=y_testUNSW_encoded,\n",
    "    labels=class_labels,\n",
    "    cats=cats,\n",
    "# Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e36e8-2d8c-4a22-a755-b86bb1f74b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Generating xgboost model dump...\n",
      "Calculating dependencies...\n",
      "Calculating pred_percentiles...\n",
      "Calculating predictions...\n",
      "Calculating ShadowDecTree for each individual decision tree...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, title=\"XGBoost UNSW\", name=\"XGBUNSW\",\n",
    "            description=\"The XGboost classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=True\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cc3f4-f77d-4a3b-84b2-cf3ed0d95e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.to_yaml(\"XGBoostUNSW_dashboard.yaml\", explainerfile=\"XGBoostUNSW_explainer.joblib\", dump_explainer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16ba507-a96b-41f6-80ff-57097db36e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8050\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x228a5a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289f33d5-ff12-4675-8706-8c8a59f9fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.terminate(8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0916f4-1941-44b7-9650-17babd1e6126",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNSW Random forest explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e873f0e-3b76-4e98-8482-786cb95b5640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected RandomForestClassifier model: Changing class type to RandomForestClassifierExplainer...\n",
      "Note: model_output=='probability', so assuming that raw shap output of RandomForestClassifier is in probability space...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "explainer = ClassifierExplainer(\n",
    "    model=rf_classifier_UNSW_Default,\n",
    "    X=X_testUNSW,\n",
    "    y=y_testUNSW_encoded,\n",
    "    labels=class_labels,\n",
    "    cats=cats,\n",
    "    shap_kwargs=dict(approximate=True)\n",
    "# Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39242f2f-db88-4359-97eb-ce739ae4962b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, mode='external', title=\"Random Forest UNSW\", name=\"RFUNSW\",\n",
    "            description=\"The Random Forest classifier with the UNSW-NB15 Dataset\", no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa640370-869a-4565-a558-ca106a124289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping configuration .yaml to C:\\Users\\LEGION\\OneDrive\\Desktop\\3rd_Year_Project_Folder\\3rd_Year_Project\\RFUNSW_dashboard.yaml...\n",
      "Dumping explainer to C:\\Users\\LEGION\\OneDrive\\Desktop\\3rd_Year_Project_Folder\\3rd_Year_Project\\RFUNSW_explainer.joblib...\n"
     ]
    }
   ],
   "source": [
    "dashboard.to_yaml(\"RFUNSW_dashboard.yaml\", explainerfile=\"RFUNSW_explainer.joblib\", dump_explainer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54a1b081-7e89-4ce1-ba6d-958d625fbf4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8070\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8070)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8070/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x221df970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8070/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:475: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:955: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:955: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:955: FutureWarning:\n",
      "\n",
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard.run(8070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e311373-2191-41a1-b452-dc0741fb1569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8050...\n"
     ]
    }
   ],
   "source": [
    "dashboard.terminate(8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0acbc4-55f5-4647-888d-3ccecb03ed43",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNSW LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e51d1b0-b569-4e1c-b720-80e9dc7eeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectKerasModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Ensure input X is reshaped to the expected format by the LSTM model\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        predictions = self.model.predict(X_reshaped)\n",
    "        # Assuming your model outputs probabilities and you need to convert these to class labels\n",
    "        return predictions.argmax(axis=-1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Reshape input X to the expected 3D format [samples, timesteps, features]\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        return self.model.predict(X_reshaped)\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = DirectKerasModelWrapper(LSTM_classifier_UNSW_Default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9af56-69a5-4352-a866-53249d6a9d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb84b072-ff68-4aa9-957e-cd4dd45af3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for DirectKerasModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testUNSW,\n",
    "    y=y_testUNSW_encoded,\n",
    "    labels=class_labels,\n",
    "    cats=cats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "346afecf-e9e6-4891-824f-f242ebee0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/LSTMUNSW_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "# Assuming `explainer` contains a TensorFlow model under `explainer.model`\n",
    "# Assuming `explainer` contains an instance of DirectKerasModelWrapper\n",
    "model_path = 'datasets/explainerDashboardFiles/LSTMUNSW_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('LSTMUNSW_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b058c020-0340-482b-ba79-fd9ae327191e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('LSTMUNSW_explainer_without_model.dill', 'rb') as file:\n",
    "    explainer = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "explainer.model = wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1304ea7-5fe7-4981-96a0-811bfd81799d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"LSTM UNSW\", name=\"LSTMUNSW\",\n",
    "            description=\"The LSTM classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df04ff49-f962-4783-8bcf-7c971d1027b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a8573409-7890-4b6c-851d-d59485be42c2/assets\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'ClassifierExplainer.shap_explainer.<locals>.model_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplainer.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexplainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'ClassifierExplainer.shap_explainer.<locals>.model_predict'"
     ]
    }
   ],
   "source": [
    "with open('explainer.pickle', 'wb') as file:\n",
    "    pickle.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ddc5db7-885b-4cc6-a804-bfb5b282e4a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://f32cc45c-a540-4bc4-bd7a-d872b5458f1c/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the explainer object\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplainer.dill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 5\u001b[0m     explainer \u001b[38;5;241m=\u001b[39m \u001b[43mdill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dill\\_dill.py:289\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, ignore, **kwds)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(file, ignore\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    Unpickle an object from a file.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \n\u001b[0;32m    287\u001b[0m \u001b[38;5;124;03m    See :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnpickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dill\\_dill.py:444\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;66;03m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mStockUnpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_main_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore:\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;66;03m# point obj class to main\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\keras\\saving\\pickle_utils.py:47\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mGFile(dest_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     46\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(archive\u001b[38;5;241m.\u001b[39mextractfile(name)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m---> 47\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msave_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:933\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    930\u001b[0m   loader \u001b[38;5;241m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m       \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m You may be trying to load on a different device \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the computational device. Consider setting the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto the io_device such as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/job:localhost\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    938\u001b[0m root \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    939\u001b[0m root\u001b[38;5;241m.\u001b[39mgraph_debug_info \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://f32cc45c-a540-4bc4-bd7a-d872b5458f1c/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a5aa9b0-fcc0-46e3-aaa0-8040dc07533b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://2e27ec86-6001-4eac-8391-e2cfcf94d0e8/assets\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "with open('LSTMUNSW_explainer.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b311c6e0-413e-4e5a-9624-802503395245",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8044\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8044)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8044/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f8e55e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8044/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run(8044)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0311149-9764-43af-8a46-4ce8af29a2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ae95173-5790-4653-bc5b-0db20addd764",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNSW Autoencoder Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10481f61-7fb3-47fc-8978-c1bdafab1d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for MockClassifier. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mock classifier to satisfy the interface required by ClassifierExplainer\n",
    "class MockClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Return a dummy prediction which is not used\n",
    "        return np.zeros((X.shape[0], 2))\n",
    "\n",
    "# Generate some dummy data to fit the mock classifier (this data is not used)\n",
    "X_dummy = np.random.rand(100, 10)\n",
    "y_dummy = np.random.randint(0, 2, 100)\n",
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy, y_dummy, test_size=0.2)\n",
    "\n",
    "# Assuming the number of features in your dummy data is 10\n",
    "feature_names = [f\"feature_{i}\" for i in range(10)]\n",
    "\n",
    "# Convert the numpy arrays to pandas DataFrames with column names\n",
    "X_train_dummy_df = pd.DataFrame(X_train_dummy, columns=feature_names)\n",
    "X_test_dummy_df = pd.DataFrame(X_test_dummy, columns=feature_names)\n",
    "\n",
    "# Instantiate and fit the mock classifier\n",
    "mock_classifier = MockClassifier()\n",
    "mock_classifier.fit(X_train_dummy_df, y_train_dummy)\n",
    "\n",
    "# Create a ClassifierExplainer with the mock classifier and dummy data\n",
    "explainer = ClassifierExplainer(mock_classifier, X_test_dummy_df, y_test_dummy, \n",
    "                                labels=['Normal', 'Anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b690e2-bc5a-422a-8b1f-df79076cbb3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard.custom import *\n",
    "from dash import dcc, html\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, precision_recall_curve\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from explainerdashboard.explainers import BaseExplainer\n",
    "\n",
    "\n",
    "class ThresholdAdjustmentComponent(ExplainerComponent):\n",
    "    def __init__(self, explainer, error_normal, error_anomalies, title=\"Threshold Adjustment\", **kwargs):\n",
    "        super().__init__(explainer, title=title)\n",
    "        self.error_normal = error_normal\n",
    "        self.error_anomalies = error_anomalies\n",
    "        # You can ignore or use kwargs as needed\n",
    "\n",
    "    def layout(self):\n",
    "        combined_errors = np.concatenate([self.error_normal, self.error_anomalies])\n",
    "        return html.Div([\n",
    "            dcc.Graph(id='accuracy_graph'),\n",
    "            dcc.Graph(id='metrics_graph'),\n",
    "            dcc.Slider(\n",
    "                id='threshold_slider',\n",
    "                min=0,\n",
    "                max=100,\n",
    "                value=50,\n",
    "                marks={i: f'{np.percentile(combined_errors, i):.2f}' for i in range(0, 101, 10)},\n",
    "                step=1,\n",
    "            ),\n",
    "            dcc.Graph(id='roc_curve_graph'),  # Placeholder for ROC curve graph\n",
    "            dcc.Graph(id='pr_curve_graph'),  # Placeholder for Precision-Recall curve graph\n",
    "            html.Pre(id='classification_report')\n",
    "        ])\n",
    "\n",
    "    def register_callbacks(self, app):\n",
    "        @app.callback(\n",
    "            [Output('accuracy_graph', 'figure'),\n",
    "             Output('metrics_graph', 'figure'),\n",
    "             Output('roc_curve_graph', 'figure'),  # New output\n",
    "             Output('pr_curve_graph', 'figure'),  # New output\n",
    "             Output('classification_report', 'children')],\n",
    "            [Input('threshold_slider', 'value')]\n",
    "        )\n",
    "        def update_graphs(slider_percentile):\n",
    "            errors = np.concatenate([self.error_normal, self.error_anomalies])\n",
    "            y_true = np.concatenate([np.zeros(len(self.error_normal)), np.ones(len(self.error_anomalies))])\n",
    "        \n",
    "            # Compute binary predictions based on the chosen threshold for classification report\n",
    "            threshold = np.percentile(errors, slider_percentile)\n",
    "            y_pred = errors > threshold\n",
    "            \n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            precision_val, recall_val, f1_val = precision_score(y_true, y_pred), recall_score(y_true, y_pred), f1_score(y_true, y_pred)\n",
    "            classification_report_text = classification_report(y_true, y_pred, target_names=['Normal', 'Anomaly'])\n",
    "        \n",
    "            # Generate metrics and confusion figures based on binary classification\n",
    "            metrics_fig, confusion_fig = self.create_figures(tn, fp, fn, tp, precision_val, recall_val, f1_val)\n",
    "        \n",
    "            # Compute ROC and PR curves using errors as scores\n",
    "            fpr, tpr, roc_thresholds = roc_curve(y_true, errors)\n",
    "            precision, recall, pr_thresholds = precision_recall_curve(y_true, errors)\n",
    "        \n",
    "            # Find closest threshold points on ROC and PR curves\n",
    "            closest_roc_index = np.argmin(np.abs(roc_thresholds - threshold))\n",
    "            closest_pr_index = np.argmin(np.abs(pr_thresholds - threshold))\n",
    "        \n",
    "            roc_curve_fig = go.Figure()\n",
    "            roc_curve_fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC Curve'))\n",
    "            # Add marker for the selected threshold\n",
    "            roc_curve_fig.add_trace(go.Scatter(x=[fpr[closest_roc_index]], y=[tpr[closest_roc_index]], mode='markers', marker_symbol='circle', marker_size=10, name='Selected Threshold'))\n",
    "        \n",
    "            pr_curve_fig = go.Figure()\n",
    "            pr_curve_fig.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name='Precision-Recall Curve'))\n",
    "            # Add marker for the selected threshold\n",
    "            pr_curve_fig.add_trace(go.Scatter(x=[recall[closest_pr_index]], y=[precision[closest_pr_index]], mode='markers', marker_symbol='circle', marker_size=10, name='Selected Threshold'))\n",
    "        \n",
    "            roc_curve_fig.update_layout(title='ROC Curve', xaxis_title='False Positive Rate', yaxis_title='True Positive Rate')\n",
    "            pr_curve_fig.update_layout(title='Precision-Recall Curve', xaxis_title='Recall', yaxis_title='Precision')\n",
    "        \n",
    "            # Return the updated figures\n",
    "            return metrics_fig, confusion_fig, roc_curve_fig, pr_curve_fig, classification_report_text\n",
    "\n",
    "\n",
    "    def calculate_accuracy(self, threshold):\n",
    "        # This method can be used if you need to calculate accuracy separately\n",
    "        pass\n",
    "    \n",
    "    def create_figures(self, tn, fp, fn, tp, precision, recall, f1):\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1 Score Indicator\n",
    "        metrics_fig = go.Figure()\n",
    "    \n",
    "        gauges_layout = [\n",
    "            {\"value\": precision, \"title\": \"Precision\", \"domain\": {'x': [0, 0.24], 'y': [0, 1]}, \"min\": 0, \"max\": 1},\n",
    "            {\"value\": recall, \"title\": \"Recall\", \"domain\": {'x': [0.26, 0.49], 'y': [0, 1]}, \"min\": 0, \"max\": 1},\n",
    "            {\"value\": f1, \"title\": \"F1 Score\", \"domain\": {'x': [0.51, 0.74], 'y': [0, 1]}, \"min\": 0, \"max\": 1},\n",
    "            {\"value\": accuracy, \"title\": \"Accuracy\", \"domain\": {'x': [0.76, 1], 'y': [0, 1]}, \"min\": 0, \"max\": 1}\n",
    "        ]\n",
    "    \n",
    "        for gauge in gauges_layout:\n",
    "            metrics_fig.add_trace(go.Indicator(\n",
    "                mode=\"number+gauge\",\n",
    "                value=gauge[\"value\"],\n",
    "                domain=gauge[\"domain\"],\n",
    "                title={'text': gauge[\"title\"]},\n",
    "                gauge={'axis': {'range': [gauge[\"min\"], gauge[\"max\"]]}, 'bar': {'color': \"darkblue\"}}\n",
    "            ))\n",
    "    \n",
    "        metrics_fig.update_layout(height=400, title=\"Precision, Recall, F1 Score, and Accuracy\")\n",
    "      \n",
    "    \n",
    "        \n",
    "        # Confusion Matrix Components Graph remains unchanged\n",
    "        confusion_fig = go.Figure(data=[\n",
    "            go.Bar(name='True Positives', x=['Metrics'], y=[tp]),\n",
    "            go.Bar(name='False Positives', x=['Metrics'], y=[fp]),\n",
    "            go.Bar(name='True Negatives', x=['Metrics'], y=[tn]),\n",
    "            go.Bar(name='False Negatives', x=['Metrics'], y=[fn])\n",
    "        ])\n",
    "        confusion_fig.update_layout(title=\"Confusion Matrix Components\",\n",
    "                                    barmode='group',\n",
    "                                    height=400)\n",
    "        \n",
    "        return metrics_fig, confusion_fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a9c3e2e-3b93-4d2c-9789-4b223c112418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Errors Type: <class 'numpy.ndarray'> Shape: (27900,)\n",
      "Anomaly Errors Type: <class 'numpy.ndarray'> Shape: (49402,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal Errors Type:\", type(AEerror_normal_loadedUNSW), \"Shape:\", np.asarray(AEerror_normal_loadedUNSW).shape)\n",
    "print(\"Anomaly Errors Type:\", type(AEerror_anomalies_loadedUNSW), \"Shape:\", np.asarray(AEerror_anomalies_loadedUNSW).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12685208-7535-42f2-8450-d544edafaacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AEerror_normal_loadedUNSWX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m combined_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mAEerror_normal_loadedUNSWX\u001b[49m, AEerror_anomalies_loadedUNSWX])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined Test Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, combined_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AEerror_normal_loadedUNSWX' is not defined"
     ]
    }
   ],
   "source": [
    "combined_test = np.concatenate([AEerror_normal_loadedUNSWX, AEerror_anomalies_loadedUNSWX])\n",
    "print(\"Combined Test Shape:\", combined_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98631557-3876-420a-af1e-cc0a5051a83b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example usage (you need to replace error_normal and error_anomalies with your actual data)\n",
    "error_normal = np.random.normal(loc=0.5, scale=0.1, size=1000)  # Hypothetical normal errors\n",
    "error_anomalies = np.random.normal(loc=0.7, scale=0.1, size=300)  # Hypothetical anomaly errors\n",
    "\n",
    "AEerror_normal_loadedUNSWX = np.asarray(AEerror_normal_loadedUNSW).flatten()  # Ensuring 1D array\n",
    "AEerror_anomalies_loadedUNSWX = np.asarray(AEerror_anomalies_loadedUNSW).flatten()  # Ensuring 1D array\n",
    "# Instantiate the custom component with the mock explainer\n",
    "# Assuming AEerror_normal_loadedUNSWX and AEerror_anomalies_loadedUNSWX are correctly shaped as shown\n",
    "threshold_component = ThresholdAdjustmentComponent(explainer, AEerror_normal_loadedUNSWX, AEerror_anomalies_loadedUNSWX)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "850c205b-d08c-432b-804f-93908283eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# Assuming `threshold_component` is your custom component and `explainer` is your Explainer object\n",
    "with open('datasets/explainers/AutoencoderUNSWfiles.dill', 'wb') as file:\n",
    "    dill.dump({'explainer': explainer, 'threshold_component': threshold_component}, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3edebe99-3a1c-49a4-9bd6-e42406edd4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard on http://192.168.1.247:8041\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8041/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1821ece80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and run the dashboard\n",
    "dashboard = ExplainerDashboard(explainer, [threshold_component])\n",
    "dashboard.run(host='127.0.0.1', port=8041)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25087235-520f-4b24-b4de-fe75e12bf40a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reinforcement Learning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b940cff-6cfb-411f-963d-725929dd7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class/action with the highest Q-value for each sample.\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Select the action with the highest Q-value for each sample\n",
    "        predicted_actions = np.argmax(q_values, axis=1)\n",
    "        return predicted_actions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts the Q-values for each action, normalized to sum to 1 (like probabilities).\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Normalize Q-values to sum to 1, so they mimic probabilities\n",
    "        q_values_normalized = q_values / q_values.sum(axis=1, keepdims=True)\n",
    "        return q_values_normalized\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = RLModelWrapper(RLDDQN_classifier_UNSW_Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9fd551d-445d-40d2-8d8c-3ab23d4a2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for RLModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testUNSW,\n",
    "    y=y_testUNSW_encoded,\n",
    "    labels=class_labels,\n",
    "    cats=cats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22a1d8dc-3bbb-4632-ac07-eea61ecb4f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"RL DDQN UNSW\", name=\"RLDDQNUNSW\",\n",
    "            description=\"The RL DDQN classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17e985be-76cc-46f1-a822-9054b5b82b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8050\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x3eed7b80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04a74c51-2a13-4391-8408-c73fe9fee9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8050...\n"
     ]
    }
   ],
   "source": [
    "dashboard3.terminate(8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76beae98-7e89-4083-ba54-7613bf9d1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/RLDDQNUNSW_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "model_path = 'datasets/explainerDashboardFiles/RLDDQNUNSW_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('RLDDQNUNSW_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc18b5e-5f8f-4926-b948-9349b1515225",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# CIC-IDS Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e777e4-9e0d-45cb-9ebe-401bdf67aff6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bda64ee-a6c0-447d-b3af-399c271f897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_testCIC = pd.read_parquet('datasets/explainerDashboardFiles/X_testCIC.parquet')\n",
    "y_test_loaded = pd.read_parquet('datasets/explainerDashboardFiles/y_testCIC.parquet')\n",
    "AEerror_normal_loadedCIC = np.load('datasets/explainerDashboardFiles/AEerror_normalCIC.npy')\n",
    "AEerror_anomalies_loadedCIC = np.load('datasets/explainerDashboardFiles/AEerror_anomaliesCIC.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bc35436-c109-4b7f-a998-071b1c4f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testCIC = y_test_loaded['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb8ff016-f49f-4050-ad4f-c0a74e8c6926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#Load Models\n",
    "rf_classifier_CIC_Default = load('datasets/explainerDashboardFiles/rf_classifierdefaultCIC.joblib')\n",
    "XGB_classifier_CIC_Default = xgb.XGBClassifier()\n",
    "XGB_classifier_CIC_Default.load_model('datasets/explainerDashboardFiles/xgb_classifierdefaultCIC.model')\n",
    "LSTM_classifier_CIC_Default = load_model('datasets/explainerDashboardFiles/lstm_modeldefaultCIC')\n",
    "RLDDQN_classifier_CIC_Default = load_model('datasets/explainerDashboardFiles/RLDDQN_modeldefaultCIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "913da3e7-0251-42e4-830f-fe108055bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the test labels\n",
    "# This assumes y_testUNSW is a pandas Series. If it's not, adjust accordingly.\n",
    "label_encoder.fit(y_testCIC)\n",
    "\n",
    "# Encode the test labels\n",
    "y_testCIC_encoded = label_encoder.transform(y_testCIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0990d6d8-787f-46a1-af81-f8dad5aabc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign', 'Bot', 'Brute Force', 'DDoS', 'DoS', 'Heartbleed', 'Infiltration', 'PortScan', 'Web Attack']\n"
     ]
    }
   ],
   "source": [
    "class_labels = y_testCIC.unique().tolist()\n",
    "class_labels.sort()\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369c71e-911c-4f7d-b7a6-21b4437dee52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## XGBoost CIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afcc1976-efe3-4f97-9136-6df565f35f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected XGBClassifier model: Changing class type to XGBClassifierExplainer...\n",
      "model_output=='probability' does not work with multiclass XGBClassifier models, so settings model_output='logodds'...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\xgboost\\core.py:160: UserWarning:\n",
      "\n",
      "[15:04:53] WARNING: D:\\bld\\xgboost-split_1705650032250\\work\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGB_classifier_UNSW_Default\n",
    "explainer = ClassifierExplainer(\n",
    "    model=XGB_classifier_CIC_Default,\n",
    "    X=X_testCIC,\n",
    "    y=y_testCIC_encoded,\n",
    "    labels=class_labels\n",
    "    # Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b4bdc25-cb37-4814-9378-18391822a1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3d1ee6-6540-484e-a585-2b8037a21f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, title=\"XGBoost CIC-IDS 2017\", name=\"XGBCIC\",\n",
    "            description=\"The XGboost classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d33b8ba-6794-4608-b815-aa32db71cf39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8050\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2ce7c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1107: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dtreeviz\\models\\shadow_decision_tree.py:335: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dtreeviz\\trees.py:420: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "Warning: Could not load \"C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\Library\\bin\\gvplugin_pango.dll\" - It was found, so perhaps one of its dependents was not.  Try ldd.\n",
      "Warning: No such file or directory while opening C:\\Users\\LEGION\\AppData\\Local\\Temp\\leaf41_23972.svg\n",
      "Error: No or improper image file=\"C:\\Users\\LEGION\\AppData\\Local\\Temp\\leaf41_23972.svg\"\n",
      "in label of node leaf41\n",
      "Warning: No such file or directory while opening C:\\Users\\LEGION\\AppData\\Local\\Temp\\leaf31_23972.svg\n",
      "Error: No or improper image file=\"C:\\Users\\LEGION\\AppData\\Local\\Temp\\leaf31_23972.svg\"\n",
      "in label of node leaf31\n",
      "Warning: no value for width of non-ASCII character 226. Falling back to width of space character\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "dashboard.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae5b1b37-3d87-4258-a65e-540d632a3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.dump('XGBoostCIC_explainer.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496ee93-b346-4bf6-9e88-278275c06e85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forest CIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cf769d4-05c2-43da-a20d-a1d44d16d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected RandomForestClassifier model: Changing class type to RandomForestClassifierExplainer...\n",
      "Note: model_output=='probability', so assuming that raw shap output of RandomForestClassifier is in probability space...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    }
   ],
   "source": [
    "#XGB_classifier_UNSW_Default\n",
    "explainer = ClassifierExplainer(\n",
    "    model=rf_classifier_CIC_Default,\n",
    "    X=X_testCIC,\n",
    "    y=y_testCIC_encoded,\n",
    "    labels=class_labels,\n",
    "    shap_kwargs=dict(approximate=True)\n",
    "\n",
    "    # Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230a47a3-2ff3-4139-8244-f3e0f9ba2fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating pred_percentiles...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, title=\"Random Forest CIC-IDS 2017\", name=\"RFCIC\",\n",
    "            description=\"The Random Forest classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4efbd02d-76da-4e0f-814b-009ad99e21f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8050\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x152b18a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [col, contribution, value]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dc6a7c2-cd87-42a0-9f9b-598ac4f0186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.dump('RFCIC_explainer.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9304d9df-40ef-4a87-b231-07cf31a8264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8050...\n"
     ]
    }
   ],
   "source": [
    "dashboard.terminate(8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7842f927-68d7-4989-be2e-44a2b6948dde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM CIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb42cec-0678-4a82-8a18-e50368298000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectKerasModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Ensure input X is reshaped to the expected format by the LSTM model\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        predictions = self.model.predict(X_reshaped)\n",
    "        # Assuming your model outputs probabilities and you need to convert these to class labels\n",
    "        return predictions.argmax(axis=-1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Reshape input X to the expected 3D format [samples, timesteps, features]\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        return self.model.predict(X_reshaped)\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = DirectKerasModelWrapper(LSTM_classifier_CIC_Default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111a90c4-aa54-4d9f-ba56-01e107a2ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for DirectKerasModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testCIC,\n",
    "    y=y_testCIC_encoded,\n",
    "    labels=class_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a8f243c-56b4-4bf0-9b02-b0dbd58605a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating prediction probabilities...\n",
      "   1/6605 [..............................] - ETA: 2:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6605/6605 [==============================] - 8s 1ms/step\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating pred_percentiles...\n",
      "Calculating predictions...\n",
      "6605/6605 [==============================] - 8s 1ms/step\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"LSTM CIC-IDS 2017\", name=\"LSTMCIC\",\n",
    "            description=\"The LSTM classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2799949-a1ba-4b27-b868-a57cace85574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8023\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8023)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8023/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x159de6f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8023/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run(8023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1db3e28a-a33f-4ece-ba98-70a1df16b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8023...\n"
     ]
    }
   ],
   "source": [
    "dashboard3.terminate(8023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13221e1d-0283-46f9-81f7-e2d984d447f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/LSTMCIC_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "# Assuming `explainer` contains a TensorFlow model under `explainer.model`\n",
    "# Assuming `explainer` contains an instance of DirectKerasModelWrapper\n",
    "model_path = 'datasets/explainerDashboardFiles/LSTMCIC_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('LSTMCIC_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e28c0aad-a058-4e43-a6f0-10b130b9b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainerDashboardFiles/LSTMCIC_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('LSTMCIC_explainer_without_model.dill', 'rb') as file:\n",
    "    explainer = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "explainer.model = wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa4e132-4d6f-4e96-92ad-4b06a5ac04d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard4 = ExplainerDashboard(explainer, title=\"LSTM CIC-IDS 2017\", name=\"LSTMCIC\",\n",
    "            description=\"The LSTM classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c573492-fda0-469f-baaf-01cd9ce02c55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CIC Autoencoder Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05d1cea9-a305-4608-9f4b-62a9de30acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for MockClassifier. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mock classifier to satisfy the interface required by ClassifierExplainer\n",
    "class MockClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Return a dummy prediction which is not used\n",
    "        return np.zeros((X.shape[0], 2))\n",
    "\n",
    "# Generate some dummy data to fit the mock classifier (this data is not used)\n",
    "X_dummy = np.random.rand(100, 10)\n",
    "y_dummy = np.random.randint(0, 2, 100)\n",
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy, y_dummy, test_size=0.2)\n",
    "\n",
    "# Assuming the number of features in your dummy data is 10\n",
    "feature_names = [f\"feature_{i}\" for i in range(10)]\n",
    "\n",
    "# Convert the numpy arrays to pandas DataFrames with column names\n",
    "X_train_dummy_df = pd.DataFrame(X_train_dummy, columns=feature_names)\n",
    "X_test_dummy_df = pd.DataFrame(X_test_dummy, columns=feature_names)\n",
    "\n",
    "# Instantiate and fit the mock classifier\n",
    "mock_classifier = MockClassifier()\n",
    "mock_classifier.fit(X_train_dummy_df, y_train_dummy)\n",
    "\n",
    "# Create a ClassifierExplainer with the mock classifier and dummy data\n",
    "explainer = ClassifierExplainer(mock_classifier, X_test_dummy_df, y_test_dummy, \n",
    "                                labels=['Normal', 'Anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1012865d-5a5f-47eb-a0bc-9283c5729e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "AEerror_normal_loadedCICX = np.asarray(AEerror_normal_loadedCIC).flatten()  # Ensuring 1D array\n",
    "AEerror_anomalies_loadedCICX = np.asarray(AEerror_anomalies_loadedCIC).flatten()  # Ensuring 1D array\n",
    "# Instantiate the custom component with the mock explainer\n",
    "# Assuming AEerror_normal_loadedUNSWX and AEerror_anomalies_loadedUNSWX are correctly shaped as shown\n",
    "threshold_component = ThresholdAdjustmentComponent(explainer, AEerror_normal_loadedCICX, AEerror_anomalies_loadedCICX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9b39aab-1d6c-40a7-bc10-69a4542a1fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard on http://192.168.1.247:8031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8031/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x19eaf580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and run the dashboard\n",
    "dashboard = ExplainerDashboard(explainer, [threshold_component])\n",
    "dashboard.run(host='127.0.0.1', port=8031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d7c095d6-bff7-49e4-bce2-89ea426c7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# Assuming `threshold_component` is your custom component and `explainer` is your Explainer object\n",
    "with open('datasets/explainers/AutoencoderCICfiles.dill', 'wb') as file:\n",
    "    dill.dump({'explainer': explainer, 'threshold_component': threshold_component}, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb454a-424d-484c-94da-c921dfc40262",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reinforcement Learning Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f5d40e4-948e-4a77-9632-0e16ead86065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class/action with the highest Q-value for each sample.\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Select the action with the highest Q-value for each sample\n",
    "        predicted_actions = np.argmax(q_values, axis=1)\n",
    "        return predicted_actions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts the Q-values for each action, normalized to sum to 1 (like probabilities).\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Normalize Q-values to sum to 1, so they mimic probabilities\n",
    "        q_values_normalized = q_values / q_values.sum(axis=1, keepdims=True)\n",
    "        return q_values_normalized\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = RLModelWrapper(RLDDQN_classifier_CIC_Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "397942d6-9165-4b23-b25d-2920baa81ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for RLModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testCIC,\n",
    "    y=y_testCIC_encoded,\n",
    "    labels=class_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "095a3806-d1e8-4de3-a29f-efa86d38b060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating prediction probabilities...\n",
      "   1/6605 [..............................] - ETA: 2:11"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6605/6605 [==============================] - 6s 879us/step\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating pred_percentiles...\n",
      "Calculating predictions...\n",
      "6605/6605 [==============================] - 6s 858us/step\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"RL DDQN CIC-IDS 2017\", name=\"RLDDQNCIC\",\n",
    "            description=\"The RL DDQN classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbc28396-a8dc-4981-a133-ccc808e8bcc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:6544\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(6544)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:6544/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fd8ffe20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:6544/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run(6544)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949ad4a-ef6f-42d8-968c-35f5f544dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3763d17-6a94-4999-bd92-5fbd42059a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/RLDDQNCIC_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "model_path = 'datasets/explainerDashboardFiles/RLDDQNCIC_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('RLDDQNCIC_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691b2a16-3022-4aac-b8eb-1459c532bd99",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# INSDN Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8fa718-6c18-45f6-a0de-66c188fdbf86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb083d98-3eed-4897-bb27-0fd8f0521448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_testINSDN = pd.read_parquet('datasets/explainerDashboardFiles/X_testINSDN.parquet')\n",
    "y_test_loaded = pd.read_parquet('datasets/explainerDashboardFiles/y_testINSDN.parquet')\n",
    "AEerror_normal_loadedINSDN = np.load('datasets/explainerDashboardFiles/AEerror_normalINSDN.npy')\n",
    "AEerror_anomalies_loadedINSDN = np.load('datasets/explainerDashboardFiles/AEerror_anomaliesINSDN.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f832e145-5fa9-496c-a114-d39fff059ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_testINSDN = y_test_loaded['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78286003-38ab-488d-aa29-dca43ae46161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "#Load Models\n",
    "rf_classifier_INSDN_Default = load('datasets/explainerDashboardFiles/rf_classifierdefaultINSDN.joblib')\n",
    "XGB_classifier_INSDN_Default = xgb.XGBClassifier()\n",
    "XGB_classifier_INSDN_Default.load_model('datasets/explainerDashboardFiles/xgb_classifierdefaultINSDN.model')\n",
    "LSTM_classifier_INSDN_Default = load_model('datasets/explainerDashboardFiles/lstm_modeldefaultINSDN')\n",
    "RLDDQN_classifier_INSDN_Default = load_model('datasets/explainerDashboardFiles/RLDDQN_modeldefaultINSDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f15cb63-64ec-4528-be6c-77f0616780a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the test labels\n",
    "# This assumes y_testUNSW is a pandas Series. If it's not, adjust accordingly.\n",
    "label_encoder.fit(y_testINSDN)\n",
    "\n",
    "# Encode the test labels\n",
    "y_testINSDN_encoded = label_encoder.transform(y_testINSDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c03aa2bf-900f-4d37-a55b-72a4b89f4a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BFA', 'BOTNET', 'DDoS', 'DoS', 'Normal', 'Probe', 'U2R', 'Web-Attack']\n"
     ]
    }
   ],
   "source": [
    "class_labels = y_testINSDN.unique().tolist()\n",
    "class_labels.sort()\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10eb24-274a-4837-a2c5-f609c4f3c963",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## XGBoost INSDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444b0acb-ad64-4c1a-baa6-c126ea8f7cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected XGBClassifier model: Changing class type to XGBClassifierExplainer...\n",
      "model_output=='probability' does not work with multiclass XGBClassifier models, so settings model_output='logodds'...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [09:54:07] WARNING: D:\\bld\\xgboost-split_1705650032250\\work\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    }
   ],
   "source": [
    "#XGB_classifier_UNSW_Default\n",
    "explainer = ClassifierExplainer(\n",
    "    model=XGB_classifier_INSDN_Default,\n",
    "    X=X_testINSDN,\n",
    "    y=y_testINSDN_encoded,\n",
    "    labels=class_labels\n",
    "    # Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d9de59-ae66-489b-aa40-557e1c8853b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, title=\"XGBoost INSDN\", name=\"XGBINSDN\",\n",
    "            description=\"The XGboost classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7ab4df3-7829-4212-84c6-0dba286466b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8050\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8050)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x148158b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f1fce5-b60d-4732-8d73-79b66ca802dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.dump('XGBoostINSDN_explainer.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2ceee7-65e7-4642-b191-9b5234a6942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8050...\n"
     ]
    }
   ],
   "source": [
    "dashboard.terminate(8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184af3b-3ca6-4e71-9f08-caaa04370e49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forest INSDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4a5131-ebb9-4ac4-b71c-71ebdd6ce736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected RandomForestClassifier model: Changing class type to RandomForestClassifierExplainer...\n",
      "Note: model_output=='probability', so assuming that raw shap output of RandomForestClassifier is in probability space...\n",
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n"
     ]
    }
   ],
   "source": [
    "#XGB_classifier_UNSW_Default\n",
    "explainer = ClassifierExplainer(\n",
    "    model=rf_classifier_INSDN_Default,\n",
    "    X=X_testINSDN,\n",
    "    y=y_testINSDN_encoded,\n",
    "    labels=class_labels,\n",
    "    shap_kwargs=dict(approximate=True)\n",
    "\n",
    "    # Pass the list of class labels here# Disable SHAP interaction calculations\n",
    "# Ensure model output is set to probability for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "756bc069-a616-4720-a368-693170a5b1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating shap values...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating prediction probabilities...\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard = ExplainerDashboard(explainer, title=\"Random Forest INSDN\", name=\"RFINSDN\",\n",
    "            description=\"The Random Forest classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eecdf16-2988-4505-9861-90264dfa3b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:2343\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(2343)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:2343/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x148ed3250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:2343/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainers.py:3497: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard.run(2343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1fdff8-b9ce-4bf6-a3fd-381002083164",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.dump('RFINSDN_explainer.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10527acc-9fc0-4a8a-9252-30da07a73e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 2343...\n"
     ]
    }
   ],
   "source": [
    "dashboard.terminate(2343)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9120622-8895-4c08-aa5c-44c3b0f0ed00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## LSTM INSDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "240b47a7-f9de-420a-b327-2de39ab461d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectKerasModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Ensure input X is reshaped to the expected format by the LSTM model\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        predictions = self.model.predict(X_reshaped)\n",
    "        # Assuming your model outputs probabilities and you need to convert these to class labels\n",
    "        return predictions.argmax(axis=-1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Reshape input X to the expected 3D format [samples, timesteps, features]\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        return self.model.predict(X_reshaped)\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = DirectKerasModelWrapper(LSTM_classifier_INSDN_Default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd236476-75db-4078-863e-f9f44e05a4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for DirectKerasModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testINSDN,\n",
    "    y=y_testINSDN_encoded,\n",
    "    labels=class_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96fa4677-2512-43a2-a53f-04a19b46f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating prediction probabilities...\n",
      "  79/3224 [..............................] - ETA: 4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224/3224 [==============================] - 4s 1ms/step\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n",
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "3224/3224 [==============================] - 4s 1ms/step\n",
      "Calculating pred_percentiles...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"LSTM INSDN\", name=\"LSTMINSDN\",\n",
    "            description=\"The LSTM classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6269dc5b-e79e-493e-ac51-0fac074554cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:8023\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(8023)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8023/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x15d4c57c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8023/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run(8023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75d59e64-3849-47a2-b6ec-80c0e64317ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/LSTMINSDN_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "# Assuming `explainer` contains a TensorFlow model under `explainer.model`\n",
    "# Assuming `explainer` contains an instance of DirectKerasModelWrapper\n",
    "model_path = 'datasets/explainerDashboardFiles/LSTMINSDN_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('LSTMINSDN_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c81e741-347f-4b32-bd8a-b54b7816363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to shut down dashboard on port 8023...\n"
     ]
    }
   ],
   "source": [
    "dashboard3.terminate(8023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa894d0a-4aef-47f2-ab39-3b9fd9c7ba7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## INSDN Autoencoder Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ba69046-6b4f-4b5a-8bc4-bf9f6c00c771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for MockClassifier. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n"
     ]
    }
   ],
   "source": [
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Mock classifier to satisfy the interface required by ClassifierExplainer\n",
    "class MockClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Return a dummy prediction which is not used\n",
    "        return np.zeros((X.shape[0], 2))\n",
    "\n",
    "# Generate some dummy data to fit the mock classifier (this data is not used)\n",
    "X_dummy = np.random.rand(100, 10)\n",
    "y_dummy = np.random.randint(0, 2, 100)\n",
    "X_train_dummy, X_test_dummy, y_train_dummy, y_test_dummy = train_test_split(X_dummy, y_dummy, test_size=0.2)\n",
    "\n",
    "# Assuming the number of features in your dummy data is 10\n",
    "feature_names = [f\"feature_{i}\" for i in range(10)]\n",
    "\n",
    "# Convert the numpy arrays to pandas DataFrames with column names\n",
    "X_train_dummy_df = pd.DataFrame(X_train_dummy, columns=feature_names)\n",
    "X_test_dummy_df = pd.DataFrame(X_test_dummy, columns=feature_names)\n",
    "\n",
    "# Instantiate and fit the mock classifier\n",
    "mock_classifier = MockClassifier()\n",
    "mock_classifier.fit(X_train_dummy_df, y_train_dummy)\n",
    "\n",
    "# Create a ClassifierExplainer with the mock classifier and dummy data\n",
    "explainer = ClassifierExplainer(mock_classifier, X_test_dummy_df, y_test_dummy, \n",
    "                                labels=['Normal', 'Anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0509b0c-77c3-479b-b40d-6ea638073b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "AEerror_normal_loadedINSDNX = np.asarray(AEerror_normal_loadedINSDN).flatten()  # Ensuring 1D array\n",
    "AEerror_anomalies_loadedINSDNX = np.asarray(AEerror_anomalies_loadedINSDN).flatten()  # Ensuring 1D array\n",
    "# Instantiate the custom component with the mock explainer\n",
    "# Assuming AEerror_normal_loadedUNSWX and AEerror_anomalies_loadedUNSWX are correctly shaped as shown\n",
    "threshold_component = ThresholdAdjustmentComponent(explainer, AEerror_normal_loadedINSDNX, AEerror_anomalies_loadedINSDNX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4519c953-c19b-483b-bd33-2a34a7f01b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard on http://192.168.1.247:8031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8031/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x17cf68580>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and run the dashboard\n",
    "dashboard = ExplainerDashboard(explainer, [threshold_component])\n",
    "dashboard.run(host='127.0.0.1', port=8031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fc84f1f-7d1a-40ce-9511-3c2fb6525a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "# Assuming `threshold_component` is your custom component and `explainer` is your Explainer object\n",
    "with open('datasets/explainers/AutoencoderINSDNfiles.dill', 'wb') as file:\n",
    "    dill.dump({'explainer': explainer, 'threshold_component': threshold_component}, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538a9e6-c7f4-48c6-a34c-1468e57a5d31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reinforcement Learning Classifier INSDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59f18a1c-e207-4afc-b973-73960b3a50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class/action with the highest Q-value for each sample.\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Select the action with the highest Q-value for each sample\n",
    "        predicted_actions = np.argmax(q_values, axis=1)\n",
    "        return predicted_actions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts the Q-values for each action, normalized to sum to 1 (like probabilities).\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Normalize Q-values to sum to 1, so they mimic probabilities\n",
    "        q_values_normalized = q_values / q_values.sum(axis=1, keepdims=True)\n",
    "        return q_values_normalized\n",
    "# Assuming LSTM_classifier_UNSW_Default is your loaded Keras model\n",
    "wrapped_model = RLModelWrapper(RLDDQN_classifier_INSDN_Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "461f42ff-1419-4400-85f4-7083e3cef347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter shap='guess', but failed to guess the type of shap explainer to use for RLModelWrapper. Defaulting to the model agnostic shap.KernelExplainer (shap='kernel'). However this will be slow, so if your model is compatible with e.g. shap.TreeExplainer or shap.LinearExplainer then pass shap='tree' or shap='linear'!\n",
      "WARNING: For shap='kernel', shap interaction values can unfortunately not be calculated!\n",
      "Note: shap values for shap='kernel' normally get calculated against X_background, but paramater X_background=None, so setting X_background=shap.sample(X, 50)...\n",
      "Generating self.shap_explainer = shap.KernelExplainer(model, X, link='identity')\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "explainer = ClassifierExplainer(\n",
    "    model=wrapped_model,\n",
    "    X=X_testINSDN,\n",
    "    y=y_testINSDN_encoded,\n",
    "    labels=class_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00db0f22-ce4e-4966-a479-8d1565d7c9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n",
      "Calculating prediction probabilities...\n",
      "  48/3224 [..............................] - ETA: 3s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3224/3224 [==============================] - 3s 909us/step\n",
      "Calculating metrics...\n",
      "Calculating confusion matrices...\n",
      "Calculating classification_dfs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating roc auc curves...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pr auc curves...\n",
      "Calculating liftcurve_dfs...\n",
      "Calculating dependencies...\n",
      "Calculating pred_percentiles...\n",
      "Calculating predictions...\n",
      "3224/3224 [==============================] - 3s 870us/step\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard3 = ExplainerDashboard(explainer, title=\"RL DDQN INSDN\", name=\"RLDDQNINSDN\",\n",
    "            description=\"The RL DDQN classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dbb03474-2882-48a7-924d-ad47d46d62b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerDashboard on http://192.168.1.247:5435\n",
      "You can terminate the dashboard with ExplainerDashboard.terminate(5435)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:5435/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1dbfcb460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:5435/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dashboard3.run(5435)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b2049-4463-410a-931f-0a4a2b529311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45f17ed0-fd84-4b32-8e94-d691f84edae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: datasets/explainerDashboardFiles/RLDDQNINSDN_modelFinal\\assets\n"
     ]
    }
   ],
   "source": [
    "model_path = 'datasets/explainerDashboardFiles/RLDDQNINSDN_modelFinal'\n",
    "explainer.model.model.save(model_path)  # Call save on the Keras model directly\n",
    "\n",
    "# Save the rest of the explainer without the model\n",
    "explainer.model = None  # Temporarily remove the model reference\n",
    "with open('RLDDQNINSDN_explainer_without_model.dill', 'wb') as file:\n",
    "    dill.dump(explainer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab3198-126c-443e-b360-6c7f26e639ef",
   "metadata": {},
   "source": [
    "# Hub for all Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89887d0d-4343-4190-9bd2-9572c6d0601c",
   "metadata": {},
   "source": [
    "### Load Explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a65179-01a8-406b-99aa-5237be2ca5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectKerasModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Ensure input X is reshaped to the expected format by the LSTM model\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        predictions = self.model.predict(X_reshaped)\n",
    "        # Assuming your model outputs probabilities and you need to convert these to class labels\n",
    "        return predictions.argmax(axis=-1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Reshape input X to the expected 3D format [samples, timesteps, features]\n",
    "        X_reshaped = X.reshape(-1, 1, X.shape[-1]) if len(X.shape) == 2 else X\n",
    "        return self.model.predict(X_reshaped)\n",
    "\n",
    "class RLModelWrapper:\n",
    "    def __init__(self, keras_model):\n",
    "        self.model = keras_model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts the class/action with the highest Q-value for each sample.\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Select the action with the highest Q-value for each sample\n",
    "        predicted_actions = np.argmax(q_values, axis=1)\n",
    "        return predicted_actions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predicts the Q-values for each action, normalized to sum to 1 (like probabilities).\"\"\"\n",
    "        # Convert DataFrame to NumPy array if necessary\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        # Predict the Q-values for the input\n",
    "        q_values = self.model.predict(X)\n",
    "        # Normalize Q-values to sum to 1, so they mimic probabilities\n",
    "        q_values_normalized = q_values / q_values.sum(axis=1, keepdims=True)\n",
    "        return q_values_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a220c5e-28e7-4b68-ae8d-6623acedac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load LSTMUNSW explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/LSTMUNSW_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/LSTMUNSW_explainer_without_model.dill', 'rb') as file:\n",
    "    LSTMexplainerUNSW = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerUNSW.model = wrapped_model\n",
    "\n",
    "# Load XGBoostUNSW explainer\n",
    "xgb_explainerUNSW = load('datasets/explainers/XGBoostUNSW_explainer.joblib')\n",
    "\n",
    "# Load RFUNSW explainer\n",
    "rf_explainerUNSW = load('datasets/explainers/RFUNSW_explainer.joblib')\n",
    "\n",
    "#Load AEUNSW\n",
    "with open('datasets/explainers/AutoencoderUNSWfiles.dill', 'rb') as file:\n",
    "    loaded_data = dill.load(file)\n",
    "\n",
    "loaded_explainerAEUNSW = loaded_data['explainer']\n",
    "loaded_threshold_componentAEUNSW = loaded_data['threshold_component']\n",
    "\n",
    "# Load RLDDQNUNSW explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/RLDDQNUNSW_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/RLDDQNUNSW_explainer_without_model.dill', 'rb') as file:\n",
    "    RLDDQNexplainerUNSW = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerUNSW.model = wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e62a13-af35-4dab-a021-c67eae05cabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTMUNSW explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/LSTMCIC_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/LSTMCIC_explainer_without_model.dill', 'rb') as file:\n",
    "    LSTMexplainerCIC = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerCIC.model = wrapped_model\n",
    "\n",
    "xgb_explainerCIC = load('datasets/explainers/XGBoostCIC_explainer.joblib')\n",
    "\n",
    "rf_explainerCIC = load('datasets/explainers/RFCIC_explainer.joblib')\n",
    "\n",
    "with open('datasets/explainers/AutoencoderCICfiles.dill', 'rb') as file:\n",
    "    loaded_data = dill.load(file)\n",
    "\n",
    "loaded_explainerAECIC = loaded_data['explainer']\n",
    "loaded_threshold_componentAECIC = loaded_data['threshold_component']\n",
    "\n",
    "# Load RLDDQNCIC explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/RLDDQNCIC_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/RLDDQNCIC_explainer_without_model.dill', 'rb') as file:\n",
    "    RLDDQNexplainerCIC = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerCIC.model = wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318b15c3-1916-4372-bad6-b2098ebc5474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load LSTMUNSW explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/LSTMINSDN_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/LSTMINSDN_explainer_without_model.dill', 'rb') as file:\n",
    "    LSTMexplainerINSDN = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerINSDN.model = wrapped_model\n",
    "\n",
    "xgb_explainerINSDN = load('datasets/explainers/XGBoostINSDN_explainer.joblib')\n",
    "\n",
    "rf_explainerINSDN = load('datasets/explainers/RFINSDN_explainer.joblib')\n",
    "\n",
    "with open('datasets/explainers/AutoencoderINSDNfiles.dill', 'rb') as file:\n",
    "    loaded_data = dill.load(file)\n",
    "\n",
    "loaded_explainerAEINSDN = loaded_data['explainer']\n",
    "loaded_threshold_componentAEINSDN = loaded_data['threshold_component']\n",
    "\n",
    "# Load RLDDQNINSDN explainer\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('datasets/explainers/RLDDQNINSDN_modelFinal')\n",
    "\n",
    "# Wrap the loaded model with your DirectKerasModelWrapper\n",
    "wrapped_model = DirectKerasModelWrapper(loaded_model)\n",
    "\n",
    "# Load the rest of the explainer\n",
    "with open('datasets/explainers/RLDDQNINSDN_explainer_without_model.dill', 'rb') as file:\n",
    "    RLDDQNexplainerINSDN = dill.load(file)\n",
    "\n",
    "# Re-attach the wrapped model to the explainer\n",
    "LSTMexplainerINSDN.model = wrapped_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b9d83d-1905-46ed-b2b7-47e726fe9bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard1 = ExplainerDashboard(rf_explainerUNSW, mode='external', title=\"Random Forest UNSW\", name=\"RFUNSW\",\n",
    "            description=\"The Random Forest classifier with the UNSW-NB15 Dataset\", no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "   , bootstrap=dbc.themes.PULSE                           \n",
    "                        \n",
    ")\n",
    "dashboard2 = ExplainerDashboard(xgb_explainerUNSW, title=\"XGBoost UNSW\", name=\"XGBUNSW\",\n",
    "            description=\"The XGboost classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard3 = ExplainerDashboard(LSTMexplainerUNSW, title=\"LSTM UNSW\", name=\"LSTMUNSW\",\n",
    "            description=\"The LSTM classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard4 = ExplainerDashboard(loaded_explainerAEUNSW, [loaded_threshold_componentAEUNSW], title=\"AE UNSW\", name=\"AEUNSW\"   , bootstrap=dbc.themes.PULSE                           \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55903cec-fc07-479a-97db-e9a0f71cec31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard5 = ExplainerDashboard(xgb_explainerCIC, title=\"XGBoost CIC-IDS 2017\", name=\"XGBCIC\",\n",
    "            description=\"The XGboost classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard6 = ExplainerDashboard(rf_explainerCIC, title=\"Random Forest CIC-IDS 2017\", name=\"RFCIC\",\n",
    "            description=\"The Random Forest classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "       , bootstrap=dbc.themes.PULSE                           \n",
    "                          \n",
    ")\n",
    "dashboard7 = ExplainerDashboard(LSTMexplainerCIC, title=\"LSTM CIC-IDS 2017\", name=\"LSTMCIC\",\n",
    "            description=\"The LSTM classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "          , bootstrap=dbc.themes.PULSE                           \n",
    "                       \n",
    ")\n",
    "dashboard8 = ExplainerDashboard(loaded_explainerAECIC, [loaded_threshold_componentAECIC], title=\"AE CIC\", name=\"AECIC\"   , bootstrap=dbc.themes.PULSE )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f77e66-359a-4725-8b23-11992bee4378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard9 = ExplainerDashboard(xgb_explainerINSDN, title=\"XGBoost INSDN\", name=\"XGBINSDN\",\n",
    "            description=\"The XGboost classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard10 = ExplainerDashboard(rf_explainerINSDN, title=\"Random Forest INSDN\", name=\"RFINSDN\",\n",
    "            description=\"The Random Forest classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=True,\n",
    "   model_summary=True,\n",
    "   contributions=True,\n",
    "   whatif=True,\n",
    "   shap_dependence=True,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "       , bootstrap=dbc.themes.PULSE                           \n",
    "                          \n",
    ")\n",
    "dashboard11 = ExplainerDashboard(LSTMexplainerINSDN, title=\"LSTM INSDN\", name=\"LSTMINSDN\",\n",
    "            description=\"The LSTM classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "                                    , bootstrap=dbc.themes.PULSE                           \n",
    "\n",
    ")\n",
    "dashboard12 = ExplainerDashboard(loaded_explainerAEINSDN, [loaded_threshold_componentAEINSDN], title=\"AE INSDN\", name=\"AEINSDN\"   , bootstrap=dbc.themes.PULSE     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9f258e-8257-4328-a2b9-baf9654cabd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\dash\\dash.py:538: UserWarning:\n",
      "\n",
      "JupyterDash is deprecated, use Dash instead.\n",
      "See https://dash.plotly.com/dash-in-jupyter for more details.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "dashboard13 = ExplainerDashboard(RLDDQNexplainerUNSW, title=\"RL DDQN UNSW\", name=\"RLDDQNUNSW\",\n",
    "            description=\"The RL DDQN classifier with the UNSW-NB15 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard14 = ExplainerDashboard(RLDDQNexplainerCIC, title=\"RL DDQN CIC-IDS 2017\", name=\"RLDDQNCIC\",\n",
    "            description=\"The RL DDQN classifier with the CIC-IDS 2017 Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")\n",
    "dashboard15 = ExplainerDashboard(RLDDQNexplainerINSDN, title=\"RL DDQN INSDN\", name=\"RLDDQNINSDN\",\n",
    "            description=\"The RL DDQN classifier with the INSDN Dataset\",\n",
    "                               mode='external', no_permutations=True, hide_poweredby=True,\n",
    "   importances=False,\n",
    "   model_summary=True,\n",
    "   contributions=False,\n",
    "   whatif=False,\n",
    "   shap_dependence=False,\n",
    "   shap_interaction=False,\n",
    "   decision_trees=False\n",
    "      , bootstrap=dbc.themes.PULSE                           \n",
    "                           \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3202ff6-dd7a-4060-9cb8-e0e56a41fd2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using random SECRET_KEY: 2e08aca4-c940-4cbd-a361-745d0435719c, please set it on your app.config[\"SECRET_KEY\"]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "{'name': 'ThresholdAdjustmentComponent', 'module': '__main__', 'params': {'error_normal': array([3.19634690e-06, 4.22591280e-06, 1.08662706e-05, ...,\n",
      "       2.73557691e-06, 6.83145479e-06, 6.47842710e-06]), 'error_anomalies': array([1.01258030e-02, 9.94211372e-03, 9.61646420e-03, ...,\n",
      "       7.62931724e-03, 9.57517952e-03, 2.30314977e-05]), 'title': 'Threshold Adjustment'}, 'component_imports': {}}\n",
      "[<custom_components.ThresholdAdjustmentComponent object at 0x000000017C2019A0>]\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "{'name': 'ThresholdAdjustmentComponent', 'module': 'custom_components', 'params': {'error_normal': array([5.25418169e-07, 2.61008854e-05, 4.51191150e-07, ...,\n",
      "       4.69807885e-07, 1.21226384e-05, 1.38777575e-06]), 'error_anomalies': array([0.00056037, 0.00281211, 0.00152621, ..., 0.00079295, 0.0034567 ,\n",
      "       0.00324035]), 'title': 'Threshold Adjustment'}, 'component_imports': {}}\n",
      "[<custom_components.ThresholdAdjustmentComponent object at 0x00000001553D9250>]\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Calculating predictions...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "{'name': 'ThresholdAdjustmentComponent', 'module': 'custom_components', 'params': {'error_normal': array([1.38464356e-06, 5.14609147e-05, 1.36131710e-04, ...,\n",
      "       2.67585924e-06, 1.40926295e-06, 2.21823736e-06]), 'error_anomalies': array([2.18595217e-02, 1.65987314e-04, 2.00872742e-04, ...,\n",
      "       3.39512972e-05, 2.38187521e-04, 1.54750503e-04]), 'title': 'Threshold Adjustment'}, 'component_imports': {}}\n",
      "[<custom_components.ThresholdAdjustmentComponent object at 0x0000000179DF3BE0>]\n",
      "Building ExplainerDashboard..\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n",
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=77302) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=211337) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Building ExplainerDashboard..\n",
      "WARNING: the number of idxs (=103167) > max_idxs_in_dropdown(=1000). However with your installed version of dash(2.15.0) dropdown search may not work smoothly. You can downgrade to `pip install dash==2.6.2` which should work better for now...\n",
      "Detected notebook environment, consider setting mode='external', mode='inline' or mode='jupyterlab' to keep the notebook interactive while the dashboard is running...\n",
      "Generating layout...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dependencies...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "hub = ExplainerHub([dashboard1,dashboard2, dashboard3, dashboard4, dashboard5,dashboard6, dashboard7, dashboard8, dashboard9, dashboard10, dashboard11, dashboard12,dashboard13,dashboard14,dashboard15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ce5b9-b003-477e-b23d-edd01afb1ca7",
   "metadata": {},
   "source": [
    "### Custom Hub layout using Dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00f531c6-2db2-400c-9f91-3f2b19ee4470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directly access the Flask application\n",
    "flask_app = hub.flask_server()\n",
    "\n",
    "# Now, you can add custom routes to the flask_app\n",
    "@flask_app.route('/')\n",
    "def home():\n",
    "    return redirect('/custom-hub')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e14e03-cb13-4cc3-98a3-c5ef0f6b3b9c",
   "metadata": {},
   "source": [
    "### Import Graphs for Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd2b78c5-fc17-4604-bd23-ccdbec27b158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON string from the file\n",
    "with open('datasets/explainers/unsw_attack_distribution.json', 'r') as f:\n",
    "    fig_json = json.load(f)\n",
    "# Convert the JSON string back into a Plotly figure object\n",
    "attackUNSWfig = plotly.graph_objs.Figure(json.loads(fig_json))\n",
    "\n",
    "with open('datasets/explainers/cic-ids_attack_distribution.json', 'r') as f:\n",
    "    fig_json = json.load(f)\n",
    "\n",
    "attackCICfig = plotly.graph_objs.Figure(json.loads(fig_json))\n",
    "\n",
    "with open('datasets/explainers/INSDN_attack_distribution.json', 'r') as f:\n",
    "    fig_json = json.load(f)\n",
    "\n",
    "attackINSDNfig = plotly.graph_objs.Figure(json.loads(fig_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4469a324-2372-4d44-a1e9-cc3348a33965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a separate Dash app for customization\n",
    "external_stylesheets = [\n",
    "    'https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css',  # Bootstrap CSS\n",
    "    'https://use.fontawesome.com/releases/v5.8.1/css/all.css'  # FontAwesome for icons\n",
    "]\n",
    "\n",
    "# Create Dash app with external stylesheets\n",
    "dash_app = Dash(__name__, server=flask_app, url_base_pathname='/custom-hub/', external_stylesheets=external_stylesheets)\n",
    "\n",
    "# Define the layout with a navigation bar and a content container\n",
    "dash_app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    html.Nav(className='navbar navbar-expand-lg navbar-dark bg-dark', children=[\n",
    "        html.Div(className='container-fluid', children=[\n",
    "            html.A('Network Anomaly Detection', href='/custom-hub/', className='navbar-brand'),\n",
    "            html.Button(html.Span(className='navbar-toggler-icon'), className='navbar-toggler', type='button',\n",
    "                        **{'data-bs-toggle': 'collapse', 'data-bs-target': '#navbarNav',\n",
    "                           'aria-controls': 'navbarNav', 'aria-expanded': 'false',\n",
    "                           'aria-label': 'Toggle navigation'}),\n",
    "            html.Div(className='collapse navbar-collapse', id='navbarNav', children=[\n",
    "                html.Ul(className='navbar-nav', children=[\n",
    "                    html.Li(html.A('Home', href='/custom-hub/', className='nav-link')),\n",
    "                    html.Li(html.A('UNSW-NB15', href='/custom-hub/unsw', className='nav-link')),\n",
    "                    html.Li(html.A('CIC-IDS 2017', href='/custom-hub/cic', className='nav-link')),\n",
    "                    html.Li(html.A('INSDN', href='/custom-hub/insdn', className='nav-link')),\n",
    "\n",
    "                    # Add more datasets as list items here\n",
    "                ])\n",
    "            ])\n",
    "        ])\n",
    "    ]),\n",
    "    html.Div(id='page-content', className='container mt-5')\n",
    "])\n",
    "\n",
    "# Callback to switch page content based on the URL\n",
    "@dash_app.callback(Output('page-content', 'children'), [Input('url', 'pathname')])\n",
    "def display_page(pathname):\n",
    "    if pathname == '/custom-hub/':\n",
    "        return html.Div([\n",
    "            html.H1(\"Network Anomaly Detection Project\", className='text-center mb-5', style={'color': '#6f42c1'}),\n",
    "            \n",
    "            dcc.Markdown(\"\"\"\n",
    "                ## Introduction\n",
    "                This project explores network anomaly detection using various machine learning algorithms.\n",
    "                Here, you'll find interactive dashboards for different datasets and the machine learning models applied to them. &#9989;  <!-- Checkmark -->\n",
    "            \"\"\", className='mb-5', dangerously_allow_html=True),  # Enable HTML rendering\n",
    "            \n",
    "            html.Div([\n",
    "                html.H2(\"Aims and Objectives\", className='mb-4', style={'color': '#6f42c1'}),\n",
    "                html.Ul([\n",
    "                    html.Li([\n",
    "                        html.Strong(\"Aim 1:\"),\n",
    "                        \" To develop an effective machine learning model capable of detecting network anomalies with high accuracy.\"\n",
    "                    ], className='mb-2'),\n",
    "                    html.Li([\n",
    "                        html.Strong(\"Aim 2:\"),\n",
    "                        \" To compare the performance of different machine learning methods (supervised, unsupervised, and reinforcement learning) and its models in the context of network security.\"\n",
    "                    ], className='mb-4'),\n",
    "                ], style={'listStyleType': 'none'}),\n",
    "                \n",
    "                html.H4(\"Objectives\", className='mb-3', style={'color': '#6f42c1'}),\n",
    "                html.Ul([\n",
    "                    html.Li([\n",
    "                        html.I(className=\"fas fa-check-circle\", style={'color': 'green'}),  # Font Awesome icon\n",
    "                        \" Implement and evaluate various machine learning algorithms for the different methods for anomaly detection.\"\n",
    "                    ], className='mb-2'),\n",
    "                    html.Li([\n",
    "                        html.I(className=\"fas fa-check-circle\", style={'color': 'green'}),\n",
    "                        \" Analyze the datasets to identify patterns and features significant for detecting network threats.\"\n",
    "                    ], className='mb-2'),\n",
    "                    html.Li([\n",
    "                        html.I(className=\"fas fa-check-circle\", style={'color': 'green'}),\n",
    "                        \" Enhance the interpretability of machine learning models to provide insights into the decision-making process.\"\n",
    "                    ], className='mb-2'),\n",
    "                ], style={'listStyleType': 'none'}),\n",
    "            ], className='aims-objectives')\n",
    "        ], className='container')\n",
    "    elif pathname == '/custom-hub/unsw':\n",
    "        return html.Div([\n",
    "            html.H2(\"Dataset: UNSW-NB15\", className='mb-4', style={'color': '#6f42c1'}),\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **Description**: The UNSW-NB15 dataset features synthetic and real network traffic,\n",
    "                including normal activities and attack behaviors, for network intrusion detection analysis. The dataset has nine types of attacks, including Fuzzers, Analysis, Backdoors, DoS, Exploits, Generic, Reconnaissance, Shellcode and Worms. \n",
    "                \"\"\", className='mb-5'),\n",
    "            dcc.Graph(figure=attackUNSWfig),\n",
    "            html.Div(className='d-grid gap-2', children=[\n",
    "                html.A('Random Forest Full Analysis', href='/dashboards/RFUNSW/', target='_blank', className='btn btn-primary'),\n",
    "                html.A('XGBoost Full Analysis', href='/dashboards/XGBUNSW/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('LSTM Classification Stats', href='/dashboards/LSTMUNSW/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('AutoEncoder Classification Stats', href='/dashboards/AEUNSW/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('Reinforcement Learning DDQN Classification Stats', href='/dashboards/RLDDQNUNSW/', target='_blank', className='btn btn-secondary')\n",
    "\n",
    "            ])\n",
    "        ])\n",
    "    # Add more elif statements for other datasets\n",
    "    elif pathname == '/custom-hub/cic':\n",
    "        return html.Div([\n",
    "            html.H2(\"Dataset: CIC-IDS 2017\", className='mb-4', style={'color': '#6f42c1'}),\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **Description**: The CIC-IDS 2017 dataset features a comprehensive set of network traffic data, \n",
    "                including a wide variety of intrusions simulated in a military network environment. It includes common attack scenarios such as DDoS, DoS, Brute Force, Heartbleed, and more, designed to benchmark intrusion detection systems.\n",
    "                \"\"\", className='mb-5'),\n",
    "            dcc.Graph(figure=attackCICfig),  \n",
    "            html.Div(className='d-grid gap-2', children=[\n",
    "                html.A('Random Forest Full Analysis', href='/dashboards/RFCIC/', target='_blank', className='btn btn-primary'),\n",
    "                html.A('XGBoost Full Analysis', href='/dashboards/XGBCIC/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('LSTM Classification Stats', href='/dashboards/LSTMCIC/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('AutoEncoder Classification Stats', href='/dashboards/AECIC/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('Reinforcement Learning DDQN Classification Stats', href='/dashboards/RLDDQNCIC/', target='_blank', className='btn btn-secondary')\n",
    "\n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "    elif pathname == '/custom-hub/insdn':\n",
    "        return html.Div([\n",
    "            html.H2(\"Dataset: inSDN\", className='mb-4', style={'color': '#6f42c1'}),\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **Description**: The inSDN dataset features a comprehensive set of network traffic data,\n",
    "                tailored specifically for evaluating security mechanisms within Software Defined Networking (SDN) environments. It includes various attack scenarios relevant to SDN infrastructures, designed to test the efficacy of intrusion detection systems in these modern networking setups.\n",
    "                \"\"\", className='mb-5'),\n",
    "            dcc.Graph(figure=attackINSDNfig),  \n",
    "            html.Div(className='d-grid gap-2', children=[\n",
    "                html.A('Random Forest Full Analysis', href='/dashboards/RFINSDN/', target='_blank', className='btn btn-primary'),\n",
    "                html.A('XGBoost Full Analysis', href='/dashboards/XGBINSDN/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('LSTM Classification Stats', href='/dashboards/LSTMINSDN/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('AutoEncoder Classification Stats', href='/dashboards/AEINSDN/', target='_blank', className='btn btn-secondary'),\n",
    "                html.A('Reinforcement Learning DDQN Classification Stats', href='/dashboards/RLDDQNINSDN/', target='_blank', className='btn btn-secondary')\n",
    "\n",
    "            ])\n",
    "        ])\n",
    "    else:\n",
    "        return '404'\n",
    "\n",
    "# Assuming you want to redirect from the root to your custom hub\n",
    "@flask_app.route('/')\n",
    "def redirect_to_hub():\n",
    "    return redirect('/custom-hub')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a4da4-f3a2-4a10-8af5-4361eba60955",
   "metadata": {},
   "source": [
    "### Run Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42686895-1d0b-4e95-9d9d-985a4e2cf5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ExplainerHub on http://0.0.0.0:8050/\n",
      " * Serving Flask app 'explainerdashboard.dashboards'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8050\n",
      " * Running on http://192.168.1.247:8050\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:10] \"GET /custom-hub/insdn HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:10] \"GET /custom-hub/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:10] \"GET /custom-hub/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:17] \"GET /custom-hub/insdn HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:17] \"GET /custom-hub/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:17] \"GET /custom-hub/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:17] \"GET /custom-hub/_favicon.ico?v=2.15.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:18] \"POST /custom-hub/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:18] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-markdown.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:18] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:18] \"GET /custom-hub/_dash-component-suites/plotly/package_data/plotly.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:18] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-highlight.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/unsw HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"POST /custom-hub/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-markdown.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:20] \"GET /custom-hub/_dash-component-suites/plotly/package_data/plotly.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:21] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-highlight.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:24] \"GET /custom-hub/insdn HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:24] \"GET /custom-hub/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:24] \"GET /custom-hub/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:24] \"POST /custom-hub/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:24] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-markdown.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:25] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:25] \"GET /custom-hub/_dash-component-suites/plotly/package_data/plotly.min.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:25] \"GET /custom-hub/_dash-component-suites/dash/dcc/async-highlight.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:28] \"GET /dashboards/RLDDQNINSDN/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/deps/polyfill@7.v2_15_0m1706769923.12.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/deps/react@16.v2_15_0m1706769923.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/deps/react-dom@16.v2_15_0m1706769923.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/deps/prop-types@15.v2_15_0m1706769923.8.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash_bootstrap_components/_components/dash_bootstrap_components.v1_5_0m1694087134.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dash-renderer/build/dash_renderer.v2_15_0m1706769923.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dcc/dash_core_components.v2_13_0m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dcc/dash_core_components-shared.v2_13_0m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/html/dash_html_components.v2_0_16m1706769923.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dash_table/bundle.v5_2_9m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:29] \"GET /dashboards/RLDDQNINSDN/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 204 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 204 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:30] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/dash/dcc/async-slider.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"GET /dashboards/RLDDQNINSDN/_dash-component-suites/plotly/package_data/plotly.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:31] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:32] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:32] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:35] \"GET /dashboards/LSTMINSDN/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/deps/polyfill@7.v2_15_0m1706769923.12.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/deps/react@16.v2_15_0m1706769923.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/deps/react-dom@16.v2_15_0m1706769923.14.0.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/deps/prop-types@15.v2_15_0m1706769923.8.1.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash_bootstrap_components/_components/dash_bootstrap_components.v1_5_0m1694087134.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dash-renderer/build/dash_renderer.v2_15_0m1706769923.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dcc/dash_core_components.v2_13_0m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dcc/dash_core_components-shared.v2_13_0m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/html/dash_html_components.v2_0_16m1706769923.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dash_table/bundle.v5_2_9m1706769923.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:36] \"GET /dashboards/LSTMINSDN/_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 204 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 204 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:37] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dcc/async-slider.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"GET /dashboards/LSTMINSDN/_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"GET /dashboards/LSTMINSDN/_dash-component-suites/plotly/package_data/plotly.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:38] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:39] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:39] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:45] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:46] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:47] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:49] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:49] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:50] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:422: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:51] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:51] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:51] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:07:51] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:01] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:01] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:01] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:01] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:02] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_plots.py:421: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "C:\\Users\\LEGION\\anaconda3\\envs\\TensorFlowGPU\\lib\\site-packages\\explainerdashboard\\explainer_methods.py:1086: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:04] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:05] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:06] \"POST /dashboards/RLDDQNINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:08] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:09] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2024 09:08:09] \"POST /dashboards/LSTMINSDN/_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "hub.run(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f6c923-f34a-4f7c-978f-fed200f30ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
